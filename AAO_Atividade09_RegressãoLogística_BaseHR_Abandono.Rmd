---
title: "Avaliando o perfil de Colaboradores que desligaram da empresa"
author: "AdelaideAlves"
date: "Fev 2024"
output: html_document
---

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

## Objetivo 

  O  foco  do  trabalho identificar a  possibilidade  de  previsao  de um funcionario pedir o
  desligamento da empresa  
  Esta  base foi  obtida  no site do **Kaggle**

  Para esse caso vamos aplicar as ferramentas: **Arvore de Decisao e Regressao Logistica**
  que sao **tecnicas supervisionadas de classificao**
  em que a variavel de interesse tem duas categforias categorias/grupos de  base  de  
  dados  real: 0 - Funcionário ativo 1- Funcionario desligado.
  

  

```{r setup, include=FALSE}

knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE) 

# echo = FALSE para não mostrar o código, apenas as saídas. 
# results = "hide" para não mostrar as saídas. 
# warning = FALSE e message = FALSE para suprimir as mensagens de aviso.

```

```{r leitura , include=FALSE}

## Leitura da base de dados 
# Ler arquivo csv

Abandono <- read.csv("HR_Abandono_2022.csv", sep=';',dec=',' , row.names=1, stringsAsFactors=TRUE)

# Quando queremos ler uma nova base podemos encontrar do lado direito "Environment" 
# e em Import Dataset  

```


#### Estamos com o arquivo na estrutura do R 

     visualizacao da base

```{r visualizando , include=FALSE}

# View(Abandono)

```


#### indicando o arquivo que serah utilizado

```{r , include=FALSE}

attach(Abandono)

```


#### mostrar as variaveis e seus respctivos formatos

```{r formatos }

str(Abandono)

```


#### verifica variavel com observacao missing


```{r verifica}

sapply(Abandono, function(x)all(is.na(x)))


```


#### descritivo das variaveis

```{r summary}

summary(Abandono)

```



#### esta tecnica eh para quando a variavel de interesse eh categorica
    pode-se notar que ela a variavel dependente eh numerica
    transformando a variavel "left" em categorica

```{r transforma}

Abandono$left<- as.factor(Abandono$left)

# verificando se a variavel mudou o formato para categorica(factor)

str(Abandono$left)

```



#### Frequencia absoluta 


```{r table}

  table(Abandono$left)
  
```


#### Frequencia relativa 
    como se trata de um estudo que trabalhamos com amostras e
    sobretudo neste caso, onde o objetivo eh estimar( classificar) 
    a pessoa em Left(1) ou Nao Left (0) uma boa opcaoo eh avaliar as tabelas 
    pelo percentual coluna, 
  

```{r frequencia}

  prop.table(table(Abandono$left))
  
```  
  
#### Como se trata de uma analise supervisionada (variavel Left eh a variavel de interesse) 
    a analise descritiva pode ser avaliar as variaveis independentes (variaveis    
    candidatas a explicar a variavel de interesse)
      
      
    Frequencia relativa - Percentual coluna 


```{r PercentualColuna}

  prop.table(table(num_project,left),2)

# Resultado com 2 casas decimais

  print(prop.table(table(num_project,left),2)*100, digits=2)
  
  
```  

 
#### Frequencia relativa - Percentual coluna Outras variaveis

```{r Outras_variaveis}

  print(prop.table(table(time_spend_company,left),2)*100, digits=2)
  
  print(prop.table(table(salary,left),2)*100, digits=2) 
  
  
```  



```{r ParteGraficas1 }


attach(Abandono)
#comando para alocar a area do PLots em 3 linhas e 2 colunas 

# histograma - variaveis quantitativas

par (mfrow=c(3,2))
hist(satisfaction_level)
hist(last_evaluation)
hist(num_project)
hist(average_montly_hours)
hist(time_spend_company)
par (mfrow=c(1,1))


``` 

#### graficamente para avaliar as variaveis quantitativas em funcao da variavel de interesse

```{r ParteGraficas2}


boxplot(Abandono$satisfaction_level~Abandono$left,main='satisfaction_level',col=c('darkgreen','red'))

boxplot(Abandono$last_evaluation ~ Abandono$left, main='last_evaluation',col=c('darkgreen','red'))

boxplot(average_montly_hours ~ Abandono$left, main='average_montly_hours',col=c('darkgreen','red'))

boxplot(time_spend_company ~ Abandono$left, main='time_spend_company ',col=c('darkgreen','red'))

``` 


#### Tratanto outliers

```{r Outliers}


# Abandono <- subset(Abandono, average_montly_hours <critério, select=c(seleção de variáveis com virgulas) )


Abandono <- subset(Abandono, average_montly_hours < 400 )

attach(Abandono)

boxplot(average_montly_hours ~ Abandono$left, main='average_montly_hours',col=c('darkgreen','red'))


``` 

#### graficamente para avaliar as variveis qualitativas em funcao da# variavel de interesse

```{r ParteGraficas3}


plot(salary, left,ylab="left",xlab="salary",col=c('red', 'darkgreen'))

plot(as.factor(num_project), left,ylab="left",xlab="number_project",col=c('red', 'darkgreen'))

plot(as.factor(Work_accident), left,ylab="left",xlab="work_accident",col=c('red', 'darkgreen'))

plot(depto, left,ylab="left",xlab="sales",col=c('red', 'darkgreen'))

plot(as.factor(promotion_last_5years), left,ylab="left",xlab="promotion_last_5years",col=c('red', 'darkgreen'))

plot(as.factor(time_spend_company), left,ylab="left",xlab="time_spend_company",col=c('red', 'darkgreen'))



``` 

#### alguns algoritmos NAO trabalham bem com a variavel qualitativa ou com muitas categorias. 
     Uma opcao eh criar variaveis "dummys"


```{r ParteGraficas4}

plot(depto, left,ylab="left",xlab="depto",col=c('red', 'darkgreen'))

``` 

```{r ParteGraficas5 , message=FALSE}

# Criando a variavel dummy  0 = Nao, 1 = Sim
Abandono$depto_1 <- ifelse(Abandono$depto=="accounting" | Abandono$depto=="Hr" ,"1","0")

Abandono$depto_2 <- ifelse(Abandono$depto=="management" | Abandono$depto=="RandD" | Abandono$depto=="product_mng" ,"1","0")


attach(Abandono)


``` 


```{r ParteGraficas6}

summary(Abandono)


plot(as.factor(depto_1), left,ylab="left",xlab="depto_1",col=c('red', 'darkgreen'))

plot(as.factor(depto_2), left,ylab="left",xlab="depto_2",col=c('red', 'darkgreen'))


 
```  

 
####  dividir em amostra Treino e amostra de validação
      Separar a sua base de dados em base de treino e base de teste.
      Amostra treino (train data) será utilizada para treinar seu modelo.
      Amostra teste (test data) refere-se à amostra de dados que será utilizada 
      para avaliar o desempenho do seu modelo, medindo a capacidade do
      modelo de generalização (se ele funciona bem em outros dados)

 
 
```{r , warning=FALSE }


attach(Abandono)

# Dividir  em duas amostra Treino e Teste, sendo treino 70% da base e teste 30% 

set.seed(1234)
ind <- sample(2,nrow(Abandono), replace=TRUE, prob=c(0.7,0.3))

table(ind)

trainData <- Abandono[ind==1, ]
testData  <- Abandono[ind==2, ]


```


```{r  aplica}
summary(trainData)

```

### Técnica Supervisionada de Classificação: A partir de uma variável target categórica

    Definir as caracteristicas que estimam essas categorias
    Existem vários algoritmos como: Árvore de Decisão, Regressão Logistica, KNN,
    Redes Neurais,RandomForest,XGBoost entre outros.
    
  

#### segundo algoritmo - Regressao Logistica 

      A regressão logística é uma técnica de análise de dados que usa matemática 
      para encontrar as relações entre uma variável target e as variáveis preditoras.
      Em seguida, essa relação é usada para prever o valor de um desses fatores com base no outro. 
   
   
```{r  ModeloInicial}

attach(trainData)


# Modelo : Regressao Logistica (glm)
# usando todas as variaveis plausiveis 

modelo_log<- glm(left ~ depto_1 + depto_2 + time_spend_company + num_project  + 
                        satisfaction_level + Work_accident + promotion_last_5years + 
                       salary, data=trainData, family=binomial(link=logit))

summary(modelo_log)

```


#### utilizando um metodo automatico de selecao de variaveis 

```{r  stepwise}

modelo_log_fim <-step(modelo_log,direction="both")

summary(modelo_log_fim)

```                

####  usando o algoritmo de regressao logistica para pontuar a base testData

 

#### Avaliar o acerto do Modelo: 
    Aplicar na base Teste e comparar o Real e o Estimado
    compara o observado: 0-nao saiu 1-saiu  com a variavel estimado pelo modelo
    modelo a partir de uma probabilidade ele tem chance de sair 


```{r  aplicando , warning=FALSE}
attach(testData)

predito_test <- predict(modelo_log_fim, testData , type = "response")

summary(predito_test)


``` 

#### Matriz de confusao: 
    compara o observado: 0-nao saiu 1-saiu  com a variavel estimado pelo modelo
    modelo a partir de uma probabilidade ele tem chance de sair 
    como a variavel estima a probabilidade podemos colocar um corte para avaliar 
    o acerto

```{r  checklog1}

fx_predito_log <- cut( predito_test, breaks=c(0,0.25,1), right=F )

plot(fx_predito_log, testData$left)


``` 


```{r  MatrizConfusao_log}


MC_log <- table(testData$left,fx_predito_log , deparse.level = 2) # montar a matriz de confusao  
show(MC_log) # mostra os resultados  

``` 


```{r  MedidaPrecisao_Acuracia}

ACC_log = sum(diag(MC_log))/sum(MC_log) # calcula a acuracia  
show(ACC_log*100) # mostra a acuracia  

``` 


```{r  MedidaPrecisao_Sensibilidade}

sensibilidade_log= (MC_log[2,2]/(MC_log[2,1]+MC_log[2,2]))*100
sensibilidade_log

``` 

#### sempre eh possivel fazer um ranking da maior probabilidade para menor probabilidade

```{r  CortesProbabilidade,include=FALSE}

testData$fx_predito1 <- cut(predito_test, breaks=c(0,0.125,0.25,0.50,1), right=F)

plot(testData$fx_predito1 , testData$left)


``` 

```{r  AplicandoBaseAbandono}

attach( Abandono)
Abandono$Predito <- predict(modelo_log_fim, Abandono, type = "response")


``` 

  
####    Arvore de Decisão:

    Metodologia estatística de fácil interpretação e utilização.
    São estruturas de dados compostas de um nó raiz e vários nós filhos,
    que por sua vez têm seus filhos também e se interligam por ramos, 
    cada um representando uma regra.
    Os nós que não possuem filhos são chamados de nós folhas e os que têm são chamados de nós pais,ou de decisão.
    Têm como objetivo encontrar regras que discriminem dois grupos previamente conhecidos.



####  Carrega o pacote: Arvore de decisao

   informacoes dos Parametros do Modelo
 
   rpart eh o algoritmo que usaremos para Arvore de Decisao
   
   #### install.packages("rpart") 
   #### install.packages("rpart.plot") 


```{r  modeloarvore}
  
library(rpart) 
library(rpart.plot) 

# vejam que a base utilizada sera a trainData, isto é a base de treino. 
# Aqui o algoritmo vai fazer uma analise onde estou indicando a variável target 


modelo_tree <- rpart (left ~ depto_1 + depto_2 + time_spend_company + 
                             num_project  + satisfaction_level + 
                             Work_accident+promotion_last_5years+salary, 
                             data=trainData, cp = 0.02,minsplit = 100 ,maxdepth=10)


```


```{r  modeloarvore_algoritmo}
  
# conteúdo do modelo

summary(modelo_tree)

```


#### Faz o Grafico, isto eh a Arvore

```{r  verarvore , message=FALSE, warning=FALSE}

rpart.plot(modelo_tree, type=4, extra=104, under=FALSE, clip.right.labs=TRUE,
           fallen.leaves=FALSE,   digits=2, varlen=-10, faclen=20,
           cex=0.4, tweak=1.7,
           compress=TRUE,
           snip=FALSE)


```

 

#### Para avaliar o desempenho desse modelo 

      vou aplicar em uma base que não foi utilizada no treinamento.
      O algoritmo aprendido na base treino vou aplicar na base teste
      
      a funcao **predict** serve para aplicar o modelo 
      (neste caso regras da arvore de decisao na base de dados)
 
 

```{r  aplicando}

previsto.tree<-predict(modelo_tree,testData,type='class')

```


#### avaliacao do modelo: comparar o observado versus o estimado:
     compara o observado: 0-nao saiu 1-saiu  com a variavel estimado pelo modelo
     modelo a partir de uma regra 
     
     Medida de Desempenho do Modelo Acurácia: 
     É a proporção de predições corretas, sem considerar o que é positivo e o que é negativo e, sim, o acerto total.
     É dada por: (VP + VN) / (VP + FN + FP + VN)
     VP verdadeiros Positivos: É da classe esperada e foi Estimado como 1
     VN verdadeiros Negativos: Não É da classe esperada e foi Estimado como 0
     FN Falsos Negativos: É da classe esperada e foi Estimado como 0
     FP Falsos Positivos: Não É da classe esperada e foi Estimado como 1



```{r  MatrizConfusao_cria}


matriz_de_confusao<-table(testData$left, previsto.tree)
matriz_de_confusao

```

```{r  Desempenho_Acuracia}

perc_acerto_tree <- sum(diag(matriz_de_confusao))/sum(matriz_de_confusao)*100
perc_acerto_tree

```

```{r  Desempenho_sensibilidade}

sensibilidade= (matriz_de_confusao[2,2]/(matriz_de_confusao[2,1]+matriz_de_confusao[2,2]))*100
sensibilidade

```
